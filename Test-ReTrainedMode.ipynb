{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "test-intro",
   "metadata": {},
   "source": [
    "## Testa den omtr√§nade modellen p√• alla testbilder\n",
    "**M√•l:**\n",
    "- Ladda den omtr√§nade modellen och k√∂ra den p√• testbilder\n",
    "- Se felklassificerade bilder\n",
    "- Analysera resultaten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-model",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms, models  # Importera models direkt\n",
    "from PIL import Image\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import psutil\n",
    "\n",
    "# Kolla batteristatus\n",
    "battery = psutil.sensors_battery()\n",
    "if battery and battery.power_plugged is False:\n",
    "    print(\"‚ö†Ô∏è Warning: Your laptop is running on battery. Performance may be reduced, \"\n",
    "          \"and CUDA might fail due to power-saving features.\")\n",
    "\n",
    "# Check CUDA availability\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"‚úÖ CUDA is available: Running on {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"‚ùå CUDA is not available: Running on CPU. Ensure your GPU drivers are installed correctly.\")\n",
    "\n",
    "# Ladda modellen och s√§tt i eval-mode\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# üõ† KORRIGERA VARNINGAR genom att anv√§nda \"weights\"\n",
    "model = models.mobilenet_v2(weights=None)  # Ist√§llet f√∂r pretrained=False\n",
    "\n",
    "# Anpassa klassificeraren\n",
    "model.classifier[1] = torch.nn.Linear(model.last_channel, 2)\n",
    "\n",
    "# Ladda tr√§nade vikter\n",
    "model.load_state_dict(torch.load('fire_classifier_retrained.pth', map_location=device))\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Definiera testmapp\n",
    "test_folders = {\n",
    "    'fire': 'dataset/fire_images',\n",
    "    'non_fire': 'dataset/non_fire_images'\n",
    "}\n",
    "\n",
    "# ‚úÖ Definiera samma transform som vid tr√§ning\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Anpassa storleken till MobileNetV2s f√∂rv√§ntade input\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalisering enligt MobileNetV2\n",
    "])\n",
    "\n",
    "print(\"‚úÖ Modell laddad och redo f√∂r testning!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c03bd10-c664-4125-acb2-f8af4f8e90df",
   "metadata": {},
   "source": [
    "## G√• igenom alla brandbilder och inte brandbilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "run-tests",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels = []\n",
    "pred_labels = []\n",
    "misclassified = []\n",
    "\n",
    "# K√∂r inferens p√• alla testbilder\n",
    "for label, folder in test_folders.items():\n",
    "    for img_name in os.listdir(folder):\n",
    "        img_path = os.path.join(folder, img_name)\n",
    "\n",
    "        # Ladda & preprocessa bilden\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        image = transform(image).unsqueeze(0).to(device)\n",
    "\n",
    "        # G√∂r en prediktion\n",
    "        with torch.no_grad():\n",
    "            output = model(image)\n",
    "            probabilities = F.softmax(output, dim=1)\n",
    "            confidence, predicted_class = torch.max(probabilities, 1)\n",
    "\n",
    "        # Konvertera etiketter till numeriskt format f√∂r confusion matrix\n",
    "        label_numeric = 1 if label == 'fire' else 0\n",
    "        predicted_numeric = predicted_class.item()\n",
    "\n",
    "        # Lagra resultat\n",
    "        true_labels.append(label_numeric)\n",
    "        pred_labels.append(predicted_numeric)\n",
    "\n",
    "        # Om felklassificerad, spara i lista\n",
    "        if predicted_numeric != label_numeric:\n",
    "            predicted_label = \"\"\n",
    "            if predicted_numeric == 1:\n",
    "                predicted_label = \"fire\"\n",
    "            else:\n",
    "                predicted_label = \"non_fire\"\n",
    "            misclassified.append((img_path, label, 'fire' if predicted_numeric == 1 else 'non_fire', confidence.item() * 100))\n",
    "            print(f'‚ùå {img_path} | True: {label} | Pred: {predicted_label} ({confidence.item() * 10:.2f}%)')\n",
    "print(f\"‚úÖ Testning klar! Totalt {len(true_labels)} bilder analyserade.\")\n",
    "print(f\"‚ùå Felklassificerade bilder: {len(misclassified)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conf-matrix",
   "metadata": {},
   "source": [
    "## üìä Visa Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conf-matrix-plot",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Skapa confusion matrix\n",
    "cm = confusion_matrix(true_labels, pred_labels)\n",
    "class_names = ['non_fire', 'fire']\n",
    "\n",
    "# Ber√§kna accuracy\n",
    "accuracy = (cm[0, 0] + cm[1, 1]) / cm.sum() * 100\n",
    "\n",
    "# Plotta confusion matrix\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.title(f\"Confusion Matrix: Test Set\\nAccuracy: {accuracy:.2f}%\")  # L√§gg till accuracy i titeln\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "misclassified-imgs",
   "metadata": {},
   "source": [
    "## ‚ùå Visa Felklassificerade Bilder\n",
    "**Vad gick fel?**\n",
    "- Visa n√•gra bilder som modellen klassificerade fel\n",
    "- J√§mf√∂r dem med en **lokal LLM (t.ex. Llama 3.2 Vision)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "show-misclassified",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "# Visa de 20 f√∂rsta felklassificerade bilderna\n",
    "for img_path, true_label, predicted_label, confidence in misclassified[:20]:\n",
    "    print(f'‚ùå {img_path} | True: {true_label} | Pred: {predicted_label} ({confidence:.2f}%)')\n",
    "    display(Image.open(img_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "llm-compare",
   "metadata": {},
   "source": [
    "## ü§ñ Llama 3.2 Vision analysera samma bilder\n",
    "Kan en **LLM f√∂rst√• bilden b√§ttre** √§n v√•r specialtr√§nade AI?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "llama-analyze",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "import textwrap\n",
    "\n",
    "# Testa en bild med Llama 3.2 Vision\n",
    "llama_image = misclassified[0][0]  # F√∂rsta felklassificerade bilden\n",
    "\n",
    "response = ollama.chat(\n",
    "    model='llama3.2-vision',\n",
    "    messages=[{\n",
    "        'role': 'user',\n",
    "        'content': 'What is in this image? Please provide reasoning step by step.',\n",
    "        'images': [llama_image]\n",
    "    }]\n",
    ")\n",
    "\n",
    "# Formatera outputen\n",
    "wrapped_response = textwrap.fill(response['message']['content'], width=80)\n",
    "\n",
    "print(f'üì∏ Bild: {llama_image}')\n",
    "display(Image.open(llama_image))\n",
    "print('\\nüß† Llama 3.2 Vision Response:\\n')\n",
    "print(wrapped_response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
